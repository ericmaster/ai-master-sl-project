{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d48b03ee",
   "metadata": {},
   "source": [
    "# Supervised Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e55a909",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218f9b4",
   "metadata": {},
   "source": [
    "Before, the EDA is carried on, the data needs to be filtered by extracting the training sessions from the `full-data` folder which contains all the training sessions from different disciplines and lengths. We are interested only in sessions that correspond to trail running and have a duration of at least 3 hours. We parse the training sessions in json format and store the metrics of interest in CSV format in the `long-tr-data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe8bc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rdflib\n",
      "  Downloading rdflib-7.1.4-py3-none-any.whl (565 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.1/565.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting isodate<1.0.0,>=0.7.2 (from rdflib)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib) (3.1.2)\n",
      "Installing collected packages: isodate, rdflib\n",
      "Successfully installed isodate-0.7.2 rdflib-7.1.4\n"
     ]
    }
   ],
   "source": [
    "# Install rdflib to use isodate\n",
    "%pip install rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f01e2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/1468 [00:00<00:24, 58.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: training-session-2023-03-18-7606603203-e51b3f6f-5e70-4fbf-b306-060ab13c8302.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/1468 [01:10<2:36:22,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to: /home/eaguayo/workspace/ml-project/data/long-tr-data/training-session-2023-03-18-7606603203-e51b3f6f-5e70-4fbf-b306-060ab13c8302.csv\n",
      "Processing time for training-session-2023-03-18-7606603203-e51b3f6f-5e70-4fbf-b306-060ab13c8302.json: 69.96 seconds\n",
      "Processing file: training-session-2021-05-16-6063407634-d69f9ab5-57fc-450a-be50-8a1d947c9014.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import isodate\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "# output_dir = \"./data/long-tr-data\"\n",
    "output_dir = \"/home/eaguayo/workspace/ml-project/data/long-tr-data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through all files in the ./full-data folder\n",
    "# input_dir = \"./data/full-data\"\n",
    "input_dir = \"/home/eaguayo/workspace/ml-project/data/full-data\"\n",
    "count = 0\n",
    "\n",
    "\n",
    "def process_file(file_name):\n",
    "    file_path = f\"{input_dir}/{file_name}\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        exercise = data.get(\"exercises\", [])[0]\n",
    "\n",
    "        # 1. check if the sport corresponds to trail running and if the duration is greater than 3 hours\n",
    "        sport = exercise.get(\"sport\")\n",
    "        duration_iso = exercise.get(\"duration\")\n",
    "        duration = isodate.parse_duration(duration_iso).total_seconds()\n",
    "\n",
    "        if sport != \"TRAIL_RUNNING\" or duration < 3 * 3600:\n",
    "            return False\n",
    "\n",
    "        # --- 2. Extract available data ---\n",
    "        print(f\"Processing file: {file_name}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        sample_features = [\n",
    "            \"heartRate\",\n",
    "            \"altitude\",\n",
    "            \"distance\",\n",
    "            \"temperature\",\n",
    "            \"cadence\",\n",
    "            \"speed\",\n",
    "        ]\n",
    "        samples = exercise.get(\"samples\", {})\n",
    "\n",
    "        # Initialize main dataframe with heart rate samples\n",
    "        df = pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    \"timestamp\": pd.to_datetime(sample[\"dateTime\"]),\n",
    "                    \"heartRate\": sample[\"value\"],\n",
    "                }\n",
    "                for sample in samples.get(\"heartRate\", [])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Process and merge other sample types\n",
    "        for sample_feature in sample_features[1:]:  # Skip heartRate (already in df)\n",
    "            sample_data = samples.get(sample_feature, [])\n",
    "            if not sample_data:\n",
    "                continue\n",
    "            temp_df = pd.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        \"timestamp\": pd.to_datetime(sample[\"dateTime\"]),\n",
    "                        sample_feature: sample[\"value\"],\n",
    "                    }\n",
    "                    for sample in sample_data\n",
    "                ]\n",
    "            )\n",
    "            df = pd.merge(df, temp_df, on=\"timestamp\", how=\"left\")\n",
    "\n",
    "        # Save the dataframe to a CSV file\n",
    "        output_file_name = f\"{output_dir}/{file_name.replace('.json', '.csv')}\"\n",
    "        df.to_csv(output_file_name, index=False)\n",
    "        end_time = time.time()\n",
    "        print(f\"Saved processed data to: {output_file_name}\")\n",
    "        print(f\"Processing time for {file_name}: {end_time - start_time:.2f} seconds\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at path: {file_name}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in file: {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred in file: {file_name} with error {e}\")\n",
    "    return False\n",
    "\n",
    "\n",
    "# Get the list of files\n",
    "files = os.listdir(input_dir)\n",
    "\n",
    "# Process files sequentially\n",
    "for file_name in tqdm(files):\n",
    "    if process_file(file_name):\n",
    "        count += 1\n",
    "\n",
    "# Process files in parallel with a progress bar\n",
    "# TODO: Does not seem to work well from vscode ipynb with local kernel \n",
    "#   or remote jupyter server runtime. Maybe split to a separate .py script file.\n",
    "# with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "#     futures = {executor.submit(process_file, file_name): file_name for file_name in files}\n",
    "#     for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "#         if future.result():\n",
    "#             count += 1\n",
    "\n",
    "print(f\"Processed {count} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2492fe",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
